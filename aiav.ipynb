{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH1enJm7vXvB",
        "outputId": "4bc69e98-8970-4312-99d1-de3c04ad3adb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/2alf/aiav.git\n",
        "!pip install pandas numpy scikit-learn joblib sklearn pefile\n",
        "\n",
        "\n",
        "import os\n",
        "import math\n",
        "import pefile\n",
        "import joblib\n",
        "import argparse\n",
        "import requests\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb8Q7C0B4Bcv"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xuOZJrpxdwF"
      },
      "outputs": [],
      "source": [
        "media_path = 'aiav/database/data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RsWI1dJ69Ml",
        "outputId": "fd33f3da-53df-4e69-d193-3fadeeef9cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total features per row: 54\n",
            "Identified important features: 13\n",
            "Now testing algorithms\n",
            "DecisionTree: 99.11%\n",
            "RandomForest: 99.45%\n",
            "GradientBoosting: 98.81%\n",
            "AdaBoost: 98.60%\n",
            "GNB: 69.93%\n",
            "\n",
            "Winner algorithm is RandomForest with a 99.45% success\n",
            "Saving algorithm and feature list in classifier directory...\n",
            "Saved\n",
            "False positive rate: 0.45%\n",
            "False negative rate: 0.81%\n"
          ]
        }
      ],
      "source": [
        "def load_data(filename=media_path):\n",
        "    \"\"\"Load and preprocess the data.\"\"\"\n",
        "    data = pd.read_csv(filename, sep='|')\n",
        "    X = data.drop(['Name', 'md5', 'legitimate'], axis=1).values\n",
        "    y = data['legitimate'].values\n",
        "    return X, y\n",
        "\n",
        "def feature_selection(X, y):\n",
        "    \"\"\"Perform feature selection using ExtraTreesClassifier.\"\"\"\n",
        "    fsel = ExtraTreesClassifier().fit(X, y)\n",
        "    model = SelectFromModel(fsel, prefit=True)\n",
        "    X_new = model.transform(X)\n",
        "    return X_new\n",
        "\n",
        "def train_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Train and evaluate various machine learning models.\"\"\"\n",
        "    algorithms = {\n",
        "        \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10),\n",
        "        \"RandomForest\": ExtraTreesClassifier(n_estimators=50),\n",
        "        \"GradientBoosting\": GradientBoostingClassifier(n_estimators=50),\n",
        "        \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "        \"GNB\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    print(\"Now testing algorithms\")\n",
        "    for algo in algorithms:\n",
        "        clf = algorithms[algo]\n",
        "        clf.fit(X_train, y_train)\n",
        "        score = clf.score(X_test, y_test)\n",
        "        print(f\"{algo}: {score * 100:.2f}%\")\n",
        "        results[algo] = score\n",
        "\n",
        "    winner = max(results, key=results.get)\n",
        "    print(f'\\nWinner algorithm is {winner} with a {results[winner] * 100:.2f}% success')\n",
        "    return algorithms[winner]\n",
        "\n",
        "def save_model(algorithm, features, output_dir='classifier/'):\n",
        "    \"\"\"Save the model and features.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print('Saving algorithm and feature list in classifier directory...')\n",
        "    joblib.dump(algorithm, os.path.join(output_dir, 'classifier.pkl'))\n",
        "    with open(os.path.join(output_dir, 'features.pkl'), 'wb') as features_file:\n",
        "        pk.dump(features, features_file)\n",
        "    print('Saved')\n",
        "\n",
        "def evaluate_performance(y_test, predictions):\n",
        "    \"\"\"Evaluate model performance.\"\"\"\n",
        "    mt = confusion_matrix(y_test, predictions)\n",
        "    false_positive_rate = (mt[0][1] / float(sum(mt[0]))) * 100\n",
        "    false_negative_rate = (mt[1][0] / float(sum(mt[1]))) * 100\n",
        "\n",
        "    print(f\"False positive rate: {false_positive_rate:.2f}%\")\n",
        "    print(f\"False negative rate: {false_negative_rate:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y = load_data()\n",
        "\n",
        "    print(f'Total features per row: {X.shape[1]}')\n",
        "\n",
        "    X_new = feature_selection(X, y)\n",
        "    nb_features = X_new.shape[1]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)\n",
        "\n",
        "    print(f'Identified important features: {nb_features}')\n",
        "\n",
        "    algorithms = train_models(X_train, X_test, y_train, y_test)\n",
        "    save_model(algorithms, features)\n",
        "\n",
        "    predictions = algorithms.predict(X_test)\n",
        "    evaluate_performance(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMQwErPF3-JE"
      },
      "source": [
        "Scan"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
